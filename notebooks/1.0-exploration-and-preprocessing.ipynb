{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cefc66f-200d-49ef-9842-e88c8eb5a2a8",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a66f2-1b5b-4760-8ee2-9c612b4956d2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca891829-27c0-4fb8-b036-7e349f6d441d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f99dd67-bec3-487b-8ce8-adc1268393d9",
   "metadata": {},
   "source": [
    "## Raw data exploration and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "670ecf25-ba11-40bc-a039-d951c2cee8b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/raw/filtered_paranmt/filtered.tsv', sep=\"\\t\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb9dc81-43a8-4038-8f85-f1280f54a690",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0  If Alkar is flooding her with psychic waste, t...   \n",
       "1                          Now you're getting nasty.   \n",
       "2           Well, we could spare your life, for one.   \n",
       "3          Ah! Monkey, you've got to snap out of it.   \n",
       "4                   I've got orders to put her down.   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309   \n",
       "1                        you're becoming disgusting.    0.749687     0.071429   \n",
       "2                      well, we can spare your life.    0.919051     0.268293   \n",
       "3                       monkey, you have to wake up.    0.664333     0.309524   \n",
       "4                         I have orders to kill her.    0.726639     0.181818   \n",
       "\n",
       "    ref_tox   trn_tox  \n",
       "0  0.014195  0.981983  \n",
       "1  0.065473  0.999039  \n",
       "2  0.213313  0.985068  \n",
       "3  0.053362  0.994215  \n",
       "4  0.009402  0.999348  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ea0b21-368c-47d2-8758-ca42ab9bc3ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 577777 entries, 0 to 577776\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   reference    577777 non-null  object \n",
      " 1   translation  577777 non-null  object \n",
      " 2   similarity   577777 non-null  float64\n",
      " 3   lenght_diff  577777 non-null  float64\n",
      " 4   ref_tox      577777 non-null  float64\n",
      " 5   trn_tox      577777 non-null  float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 30.9+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad65a1c-6f5f-42c0-bff4-f288eacf952c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>577777.000000</td>\n",
       "      <td>577777.000000</td>\n",
       "      <td>577777.000000</td>\n",
       "      <td>577777.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.758469</td>\n",
       "      <td>0.157652</td>\n",
       "      <td>0.541372</td>\n",
       "      <td>0.434490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.092695</td>\n",
       "      <td>0.108057</td>\n",
       "      <td>0.457571</td>\n",
       "      <td>0.458904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.600001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.681105</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.754439</td>\n",
       "      <td>0.141791</td>\n",
       "      <td>0.806795</td>\n",
       "      <td>0.085133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.831244</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.990469</td>\n",
       "      <td>0.973739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.999724</td>\n",
       "      <td>0.999730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          similarity    lenght_diff        ref_tox        trn_tox\n",
       "count  577777.000000  577777.000000  577777.000000  577777.000000\n",
       "mean        0.758469       0.157652       0.541372       0.434490\n",
       "std         0.092695       0.108057       0.457571       0.458904\n",
       "min         0.600001       0.000000       0.000033       0.000033\n",
       "25%         0.681105       0.066667       0.012171       0.000707\n",
       "50%         0.754439       0.141791       0.806795       0.085133\n",
       "75%         0.831244       0.238095       0.990469       0.973739\n",
       "max         0.950000       0.400000       0.999724       0.999730"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "259e68ab-8eb8-4c74-b08e-cca641a28225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. reference toxicity: 0.5413717990275281\n"
     ]
    }
   ],
   "source": [
    "print(f\"Avg. reference toxicity: {dataset['ref_tox'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0fb62a3-2904-4073-8566-bc6edccd8e21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. translation toxicity: 0.4344898352213311\n"
     ]
    }
   ],
   "source": [
    "print(f\"Avg. translation toxicity: {dataset['trn_tox'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68cc7bd3-6ff3-478d-bb16-4d2af84b6ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    319142\n",
      "True     258635\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((dataset['trn_tox'] >= dataset['ref_tox']).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31542e8-449d-4b8a-8d32-638b5c82b712",
   "metadata": {},
   "source": [
    "### The data is inconsistent. Reference needs to be switched around pairwise for values and sentences because it's not always less harmful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093978dd-157e-4cd0-99b8-9ed65c014d36",
   "metadata": {},
   "source": [
    "# Data preprocessing (the copy of the code from src.data.make_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7e4e65-8e9f-4977-a970-903c2f30c023",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57dd818d-cdc5-47de-b802-65613a3ca8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Darya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Darya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Darya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddd4e55-9faa-4723-b023-c5df32a0cba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Class MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dd642d0-8e8f-4114-816b-1738812be6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.raw_data = pd.read_csv(data_path, sep='\\t', index_col=0)\n",
    "        \n",
    "        data = pd.DataFrame()\n",
    "        data['toxic'] = pd.concat([self.raw_data[self.raw_data['ref_tox'] > self.raw_data['trn_tox']]['reference'], self.raw_data[self.raw_data['ref_tox'] < self.raw_data['trn_tox']]['translation']])\n",
    "        data['normal'] = pd.concat([self.raw_data[self.raw_data['ref_tox'] > self.raw_data['trn_tox']]['translation'], self.raw_data[self.raw_data['ref_tox'] < self.raw_data['trn_tox']]['reference']])\n",
    "        data['toxic_reduction'] = abs(self.raw_data['ref_tox'] - self.raw_data['trn_tox'])\n",
    "        self.data = data\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.iloc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264177f6-671d-4764-850b-cb2fba584c4b",
   "metadata": {},
   "source": [
    "## Prepare tha data, create dataset, transform and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74bdc49d-435f-412d-8a07-9bff96646fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # replace punctuation with spaces\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n",
    "    \n",
    "    # remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # remove non-ascii characters\n",
    "    text = text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    \n",
    "    # remove urls\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # remove html tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360db100-ef16-4896-a2dc-06172ba95ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    \n",
    "    data_dir = \"../data/raw/filtered_paranmt/\"\n",
    "    dataset_path = \"../data/interim/text_dataset.pkl\"\n",
    "    filename = \"filtered.tsv\"\n",
    "    \n",
    "    \n",
    "    # create dataset\n",
    "    dataset = MyDataset(os.path.join(data_dir, filename))\n",
    "    \n",
    "\n",
    "    # transform dataset\n",
    "    # clear text\n",
    "    dataset.data.toxic = dataset.data.toxic.apply(clean_text)\n",
    "    dataset.data.normal = dataset.data.normal.apply(clean_text)\n",
    "\n",
    "    # tokenize text\n",
    "    dataset.data.toxic = dataset.data.toxic.apply(word_tokenize)\n",
    "    dataset.data.normal = dataset.data.normal.apply(word_tokenize)\n",
    "\n",
    "    # remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    dataset.data.toxic = dataset.data.toxic.apply(lambda text: [word for word in text if word not in stop_words])\n",
    "    dataset.data.normal = dataset.data.normal.apply(lambda text: [word for word in text if word not in stop_words])\n",
    "    \n",
    "    # lemmatize text\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    dataset.data.toxic = dataset.data.toxic.apply(lambda text: [lemmatizer.lemmatize(word) for word in text])\n",
    "    dataset.data.normal = dataset.data.normal.apply(lambda text: [lemmatizer.lemmatize(word) for word in text])\n",
    "    \n",
    "    \n",
    "    # save dataset\n",
    "    if not os.path.exists(os.path.dirname(dataset_path)):\n",
    "        os.makedirs(os.path.dirname(dataset_path))\n",
    "    pickle.dump(dataset, open(dataset_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1578516-708a-4d2a-9a2e-e54719328b01",
   "metadata": {},
   "source": [
    "## Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ee75c7d-81a8-4d5f-9611-4360828dda60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open('../data/interim/text_dataset.pkl', 'rb')).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d67102d9-2c33-4a6c-9804-e1770c7135ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>normal</th>\n",
       "      <th>toxic_reduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[gon, na, child, genetic, disorder, gon, na, d...</td>\n",
       "      <td>[going, breed, kid, genetic, disorder, make, die]</td>\n",
       "      <td>0.915109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[laughing, u, kick, as]</td>\n",
       "      <td>[laughing, u, show]</td>\n",
       "      <td>0.999361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[maine, short, black, people, back]</td>\n",
       "      <td>[much, black, maine]</td>\n",
       "      <td>0.814971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[spirit, cursed, walking, back, road, waterway...</td>\n",
       "      <td>[soul, cursed, guard, path, say, encounter, un...</td>\n",
       "      <td>0.698517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[come, cal, leave, shit, alone]</td>\n",
       "      <td>[come, cal, put]</td>\n",
       "      <td>0.999357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                toxic  \\\n",
       "5   [gon, na, child, genetic, disorder, gon, na, d...   \n",
       "6                             [laughing, u, kick, as]   \n",
       "7                 [maine, short, black, people, back]   \n",
       "11  [spirit, cursed, walking, back, road, waterway...   \n",
       "13                    [come, cal, leave, shit, alone]   \n",
       "\n",
       "                                               normal  toxic_reduction  \n",
       "5   [going, breed, kid, genetic, disorder, make, die]         0.915109  \n",
       "6                                 [laughing, u, show]         0.999361  \n",
       "7                                [much, black, maine]         0.814971  \n",
       "11  [soul, cursed, guard, path, say, encounter, un...         0.698517  \n",
       "13                                   [come, cal, put]         0.999357  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e4515-eaf4-4945-86d4-402a86050144",
   "metadata": {},
   "source": [
    "### Let's explore the toxic and normal words in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a04f7793-c471-44f3-bcfd-5daea1f9ec11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toxic_words = list(set([word for sentence in df['toxic'].values for word in sentence]).difference(set([word for sentence in df['normal'].values for word in sentence])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cac52305-3a15-4851-aca6-05450a862b93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shirshu',\n",
       " 'indio',\n",
       " 'cornishman',\n",
       " 'useg',\n",
       " 'rosette',\n",
       " 'torrturing',\n",
       " 'godzillawill',\n",
       " 'pervading',\n",
       " 'joely',\n",
       " 'nurtured',\n",
       " 'schlecks',\n",
       " 'swrong',\n",
       " 'luminescent',\n",
       " 'goif',\n",
       " 'ekes',\n",
       " 'seminiferous',\n",
       " 'cvalda',\n",
       " 'mirthless',\n",
       " 'blp',\n",
       " 'eidu']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9be39549-bb76-481f-9060-ac702554022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/interim/toxic_words.pkl', 'wb') as f:\n",
    "    pickle.dump(toxic_words, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7723ba-c96b-43fb-85b7-13d981006a1c",
   "metadata": {},
   "source": [
    "### Many of the words in this collection are simply misspelled words or phrases that don't belong in sentences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
